{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session 1: Unconstrained Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.9651767755928296 -0.0008783822703435362 -672.1388451473379\n"
     ]
    }
   ],
   "source": [
    "# Ex1:\n",
    "\n",
    "def f(x):\n",
    "    return x**4 - 2*x**3 - 64*x**2 + 2*x + 63\n",
    "\n",
    "def df(x):\n",
    "    return 4*x**3 - 6*x**2 - 128*x + 2\n",
    "\n",
    "def myGrad(x0=0, df=df, learning_rate=0.005, n_iterations=1000):\n",
    "    X = [x0]\n",
    "    for _ in range(n_iterations):\n",
    "        X.append(X[-1] - learning_rate*df(X[-1]))\n",
    "        if np.abs(df(X[-1])) < 1e-3:\n",
    "            break\n",
    "    return X[-1]\n",
    "\n",
    "x = myGrad()\n",
    "print(x, df(x), f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333342418542005 0.3333324740327973 -0.3333333333325502 9.577411983485717e-07 -8.100802049160194e-07\n"
     ]
    }
   ],
   "source": [
    "# Ex2: f(x, y) = x^2 + y^2 + xy - x - y\n",
    "\n",
    "def f(x, y):\n",
    "    return x**2 + y**2 + x*y - x - y\n",
    "\n",
    "def dfx(x, y):\n",
    "    return 2*x + y - 1\n",
    "\n",
    "def dfy(x, y):\n",
    "    return 2*y + x - 1\n",
    "\n",
    "def myGD(x0=0, y0=0, dfx=dfx, dfy=dfy, learning_rate=0.1, n_iterations=1000):\n",
    "    X = [x0]\n",
    "    Y = [y0]\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        X.append(X[-1] - learning_rate*dfx(X[-1], Y[-1]))\n",
    "        Y.append(Y[-1] - learning_rate*dfy(X[-1], Y[-1]))\n",
    "\n",
    "        if abs(dfx(X[-1], Y[-1])) < 1e-6 and abs(dfy(X[-1], Y[-1])) < 1e-6:\n",
    "            break\n",
    "    \n",
    "    return X[-1], Y[-1]\n",
    "\n",
    "x, y = myGD()\n",
    "print(x, y, f(x, y), dfx(x, y), dfy(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1.] [-2.22044605e-16  3.33066907e-16  0.00000000e+00] 1.6023737137301802e-31 -1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Ex1: f(x) = x1^2 + x2^2 + x3^2 - x1x2 - x2x3 + x1 + x3\n",
    "\n",
    "def d2f():\n",
    "    return np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]])\n",
    "\n",
    "def df(x):\n",
    "    return np.array([2*x[0] - x[1] + 1, 2*x[1] - x[0] - x[2], 2*x[2] - x[1] + 1])\n",
    "\n",
    "def f(x):\n",
    "    return x[0]**2 + x[1]**2 + x[2]**2 -x[0]*x[1] - x[1]*x[2] + x[0] + x[2]\n",
    "\n",
    "def Newton(df=df, d2f=d2f, x=np.random.rand(3)):\n",
    "    \n",
    "    while np.sqrt((df(x)[0] ** 2 + df(x)[1] ** 2 + df(x)[2] ** 2)) >= 1e-6:\n",
    "        x = x - np.linalg.inv(d2f()).dot(df(x))\n",
    "    \n",
    "    return x\n",
    "\n",
    "x = Newton()\n",
    "print(x, df(x), df(x)[0] ** 2 + df(x)[1] ** 2 + df(x)[2] ** 2, f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1: f(x) = x1^2 + x2^2 + x3^2 - x1x2 - x2x3 + x1 + x3\n",
    "\n",
    "def d2f():\n",
    "    return np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]])\n",
    "\n",
    "def df(x):\n",
    "    return np.array([2*x[0] - x[1] + 1, 2*x[1] - x[0] - x[2], 2*x[2] - x[1] + 1])\n",
    "\n",
    "def f(x):\n",
    "    return x[0]**2 + x[1]**2 + x[2]**2 -x[0]*x[1] - x[1]*x[2] + x[0] + x[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session 2: Constrained Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Lagrangian function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1: Find maximum and minimum of f(x, y) = xy where g(x, y) = 10x + 20y - 400 = 0\n",
    "\n",
    "def f(x, y):\n",
    "    return x*y\n",
    "\n",
    "def L(x, y, a):\n",
    "    return f(x, y) - a * (10*x + 20*y - 400)\n",
    "\n",
    "def dL(x, y, a):\n",
    "    return (y - 10, x - 10, 10*x + 20*y - 400)\n",
    "\n",
    "def solve(x0=0, y0=0, func=f, LargrangianFunc=L, derLarg=dL):\n",
    "    x = [x0]\n",
    "    y = [y0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
